{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11227979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Qubit state dataset saved to: ../data/raw/qubit_states_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_qubit_states(n_samples: int = 5000, seed: int = 42, include_bloch: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a dataset of normalized qubit states:\n",
    "        |ψ⟩ = α|0⟩ + β|1⟩, where |α|² + |β|² = 1\n",
    "\n",
    "    Parameters:\n",
    "        n_samples (int): Number of qubit states to generate.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "        include_bloch (bool): Whether to include Bloch sphere coordinates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with complex coefficients and optional Bloch coordinates.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        alpha = np.random.randn() + 1j * np.random.randn()\n",
    "        beta = np.random.randn() + 1j * np.random.randn()\n",
    "        \n",
    "        norm = np.sqrt(np.abs(alpha)**2 + np.abs(beta)**2)\n",
    "        alpha /= norm\n",
    "        beta /= norm\n",
    "\n",
    "        record = {\n",
    "            \"alpha_real\": alpha.real,\n",
    "            \"alpha_imag\": alpha.imag,\n",
    "            \"beta_real\": beta.real,\n",
    "            \"beta_imag\": beta.imag,\n",
    "            \"norm_check\": np.abs(alpha)**2 + np.abs(beta)**2,\n",
    "        }\n",
    "\n",
    "        if include_bloch:\n",
    "            theta = 2 * np.arccos(np.abs(alpha))\n",
    "            phi = (np.angle(beta) - np.angle(alpha)) % (2 * np.pi)\n",
    "\n",
    "            bloch_x = np.sin(theta) * np.cos(phi)\n",
    "            bloch_y = np.sin(theta) * np.sin(phi)\n",
    "            bloch_z = np.cos(theta)\n",
    "\n",
    "            record.update({\n",
    "                \"theta\": theta,\n",
    "                \"phi\": phi,\n",
    "                \"bloch_x\": bloch_x,\n",
    "                \"bloch_y\": bloch_y,\n",
    "                \"bloch_z\": bloch_z,\n",
    "            })\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = generate_qubit_states(n_samples=5000, seed=2025)\n",
    "    output_path = \"../data/raw/qubit_states_dataset.csv\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Qubit state dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ed1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalized qubit dataset saved to: ../data/raw/qubit_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_normalized_qubit_states(n_samples: int = 5000, seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a dataset of normalized qubit states of the form:\n",
    "        |ψ⟩ = α|0⟩ + β|1⟩\n",
    "    such that:\n",
    "        |α|^2 + |β|^2 = 1\n",
    "\n",
    "    Returns a DataFrame with complex amplitudes and Bloch sphere coordinates.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "   \n",
    "        alpha = np.random.randn() + 1j * np.random.randn()\n",
    "        beta = np.random.randn() + 1j * np.random.randn()\n",
    "\n",
    " \n",
    "        norm = np.sqrt(np.abs(alpha)**2 + np.abs(beta)**2)\n",
    "        alpha /= norm\n",
    "        beta /= norm\n",
    "\n",
    "    \n",
    "        theta = 2 * np.arccos(np.abs(alpha))\n",
    "        phi = np.angle(beta) - np.angle(alpha)\n",
    "\n",
    "   \n",
    "        x = np.sin(theta) * np.cos(phi)\n",
    "        y = np.sin(theta) * np.sin(phi)\n",
    "        z = np.cos(theta)\n",
    "\n",
    "        data.append({\n",
    "            \"alpha_real\": alpha.real,\n",
    "            \"alpha_imag\": alpha.imag,\n",
    "            \"beta_real\": beta.real,\n",
    "            \"beta_imag\": beta.imag,\n",
    "            \"|α|²\": np.abs(alpha)**2,\n",
    "            \"|β|²\": np.abs(beta)**2,\n",
    "            \"norm_check\": np.abs(alpha)**2 + np.abs(beta)**2,\n",
    "            \"theta\": theta,\n",
    "            \"phi\": phi,\n",
    "            \"bloch_x\": x,\n",
    "            \"bloch_y\": y,\n",
    "            \"bloch_z\": z\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_path = \"../data/raw/qubit_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    df = generate_normalized_qubit_states()\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"✅ Normalized qubit dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df32554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Density matrix dataset saved to: ../data/raw/density_matrices.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_pure_state() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a single normalized qubit pure state vector |ψ⟩ = α|0⟩ + β|1⟩\n",
    "    \"\"\"\n",
    "    alpha = np.random.randn() + 1j * np.random.randn()\n",
    "    beta = np.random.randn() + 1j * np.random.randn()\n",
    "    norm = np.sqrt(np.abs(alpha)**2 + np.abs(beta)**2)\n",
    "    return np.array([alpha, beta]) / norm\n",
    "\n",
    "\n",
    "def compute_density_matrix(states: list[np.ndarray], probs: list[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the density matrix: ρ = Σ p_i |ψ_i⟩⟨ψ_i|\n",
    "    \"\"\"\n",
    "    rho = np.zeros((2, 2), dtype=complex)\n",
    "    for psi, p in zip(states, probs):\n",
    "        outer_product = np.outer(psi, np.conjugate(psi))\n",
    "        rho += p * outer_product\n",
    "    return rho\n",
    "\n",
    "\n",
    "def generate_density_matrices(n_samples: int = 5000, n_components: int = 3, seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a dataset of 2x2 density matrices.\n",
    "    Each matrix is a mixture of `n_components` pure states.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        # Generate n_components pure states\n",
    "        states = [generate_pure_state() for _ in range(n_components)]\n",
    "        probs = np.random.dirichlet(np.ones(n_components))  # ensures ∑p_i = 1\n",
    "\n",
    "        # Compute the density matrix\n",
    "        rho = compute_density_matrix(states, probs)\n",
    "\n",
    "        # Flatten real and imaginary parts for dataset\n",
    "        data.append({\n",
    "            \"rho_00_real\": rho[0, 0].real,\n",
    "            \"rho_00_imag\": rho[0, 0].imag,\n",
    "            \"rho_01_real\": rho[0, 1].real,\n",
    "            \"rho_01_imag\": rho[0, 1].imag,\n",
    "            \"rho_10_real\": rho[1, 0].real,\n",
    "            \"rho_10_imag\": rho[1, 0].imag,\n",
    "            \"rho_11_real\": rho[1, 1].real,\n",
    "            \"rho_11_imag\": rho[1, 1].imag,\n",
    "            \"trace\": np.trace(rho).real,\n",
    "            \"purity\": np.real(np.trace(rho @ rho))  # Tr(ρ²)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_path = \"../data/raw/density_matrices.csv\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    df = generate_density_matrices()\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"✅ Density matrix dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77fdd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Born Rule dataset saved to: ../data/raw/born_rule_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_born_rule_dataset(n_samples: int = 5000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate dataset showing measurement probabilities using the Born Rule.\n",
    "\n",
    "    Formula: P(i) = ⟨ψ| Mi† Mi |ψ⟩\n",
    "\n",
    "    Parameters:\n",
    "        n_samples (int): Number of samples to generate.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with ψ, Mi, and P(i)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "       \n",
    "        alpha = np.random.randn() + 1j * np.random.randn()\n",
    "        beta = np.random.randn() + 1j * np.random.randn()\n",
    "        norm = np.sqrt(np.abs(alpha)**2 + np.abs(beta)**2)\n",
    "        alpha /= norm\n",
    "        beta /= norm\n",
    "        psi = np.array([[alpha], [beta]])\n",
    "\n",
    "        Mi = np.random.randn(2, 2) + 1j * np.random.randn(2, 2)\n",
    "\n",
    "        Mi_dagger_Mi = Mi.conj().T @ Mi\n",
    "        prob = np.vdot(psi, Mi_dagger_Mi @ psi).real  # real part only\n",
    "\n",
    "        records.append({\n",
    "            \"alpha_real\": alpha.real,\n",
    "            \"alpha_imag\": alpha.imag,\n",
    "            \"beta_real\": beta.real,\n",
    "            \"beta_imag\": beta.imag,\n",
    "            \"probability\": prob\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = generate_born_rule_dataset()\n",
    "    df.to_csv(\"../data/raw/born_rule_dataset.csv\", index=False)\n",
    "    print(\"✅ Born Rule dataset saved to: ../data/raw/born_rule_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd682fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Expectation Value dataset saved to: ../data/raw/expectation_value_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_expectation_dataset(n_samples: int = 5000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate dataset for expectation value of observable:\n",
    "        ⟨O⟩ = ⟨ψ| O |ψ⟩\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of data points to generate.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset of qubit state and expectation value.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        # Generate a random normalized qubit state |ψ⟩ = α|0⟩ + β|1⟩\n",
    "        alpha = np.random.randn() + 1j * np.random.randn()\n",
    "        beta = np.random.randn() + 1j * np.random.randn()\n",
    "        norm = np.sqrt(np.abs(alpha)**2 + np.abs(beta)**2)\n",
    "        alpha /= norm\n",
    "        beta /= norm\n",
    "        psi = np.array([[alpha], [beta]])\n",
    "\n",
    "        # Create a random 2x2 Hermitian observable Ô\n",
    "        a = np.random.randn()\n",
    "        b = np.random.randn()\n",
    "        c = np.random.randn()\n",
    "        d = np.random.randn()\n",
    "        observable = np.array([\n",
    "            [a, b + 1j*c],\n",
    "            [b - 1j*c, d]\n",
    "        ])  # Hermitian by construction\n",
    "\n",
    "        # Calculate expectation value: ⟨O⟩ = ⟨ψ| O |ψ⟩\n",
    "        psi_dagger = psi.conj().T\n",
    "        expectation = (psi_dagger @ observable @ psi).item().real  # Take real part\n",
    "\n",
    "        records.append({\n",
    "            \"alpha_real\": alpha.real,\n",
    "            \"alpha_imag\": alpha.imag,\n",
    "            \"beta_real\": beta.real,\n",
    "            \"beta_imag\": beta.imag,\n",
    "            \"obs_00\": a,\n",
    "            \"obs_01_real\": b,\n",
    "            \"obs_01_imag\": c,\n",
    "            \"obs_11\": d,\n",
    "            \"expectation_value\": expectation\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = generate_expectation_dataset()\n",
    "    df.to_csv(\"../data/raw/expectation_value_dataset.csv\", index=False)\n",
    "    print(\"✅ Expectation Value dataset saved to: ../data/raw/expectation_value_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7372fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Simulated feature map dataset saved to: ../data/raw/simulated_feature_map_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "def simulate_feature_map(x: List[float]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate a quantum feature map using trigonometric functions.\n",
    "\n",
    "    Args:\n",
    "        x (List[float]): Input features.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Simulated 'statevector' with real and imaginary parts.\n",
    "    \"\"\"\n",
    "    # Example feature map using trigonometric encoding\n",
    "    reals = np.cos(x)\n",
    "    imags = np.sin(x)\n",
    "    \n",
    "    # Simulate complex statevector (normalize to unit length)\n",
    "    statevector = reals + 1j * imags\n",
    "    statevector /= np.linalg.norm(statevector)\n",
    "    \n",
    "    return statevector\n",
    "\n",
    "def generate_simulated_dataset(n_samples: int = 3000, n_features: int = 3, seed: int = 42) -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        x = np.random.uniform(-np.pi, np.pi, size=n_features)\n",
    "        statevector = simulate_feature_map(x)\n",
    "\n",
    "        record = {\n",
    "            **{f\"x{i+1}\": val for i, val in enumerate(x)},\n",
    "            **{f\"amp_{i}_real\": amp.real for i, amp in enumerate(statevector)},\n",
    "            **{f\"amp_{i}_imag\": amp.imag for i, amp in enumerate(statevector)}\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUTPUT_PATH = \"../data/raw/simulated_feature_map_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    df = generate_simulated_dataset(n_samples=3000, n_features=3)\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    print(f\"✅ Simulated feature map dataset saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96cd6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantum kernel data saved to: ../data/raw/quantum_kernel_data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def simulate_feature_map(x):\n",
    "    \"\"\"Simulate a quantum feature map φ(x) using normalized sin/cos embedding.\"\"\"\n",
    "    re = np.cos(x)\n",
    "    im = np.sin(x)\n",
    "    phi = re + 1j * im\n",
    "    return phi / np.linalg.norm(phi)\n",
    "\n",
    "def quantum_kernel(x, x_prime):\n",
    "    \"\"\"Compute K(x, x') = |⟨φ(x)|φ(x')⟩|²\"\"\"\n",
    "    phi_x = simulate_feature_map(x)\n",
    "    phi_xp = simulate_feature_map(x_prime)\n",
    "    return np.abs(np.vdot(phi_x, phi_xp))**2\n",
    "\n",
    "def generate_data(n=5000, n_features=3, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        x = np.random.rand(n_features) * 2 * np.pi\n",
    "        x_prime = np.random.rand(n_features) * 2 * np.pi\n",
    "        k_val = quantum_kernel(x, x_prime)\n",
    "        data.append(np.concatenate([x, x_prime, [k_val]]))\n",
    "\n",
    "    columns = [f'x{i+1}' for i in range(n_features)] + \\\n",
    "              [f\"x{i+1}'\" for i in range(n_features)] + ['K(x,x\\')']\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Create and save the dataset\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "df = generate_data(n=5000, n_features=3)\n",
    "csv_path = \"../data/raw/quantum_kernel_data.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Quantum kernel data saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hadamard data saved to: ../data/raw/hadamard_data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def random_qubit_state():\n",
    "    \"\"\"Generate a random normalized single-qubit state |ψ⟩ = a|0⟩ + b|1⟩\"\"\"\n",
    "    a = np.random.rand() + 1j * np.random.rand()\n",
    "    b = np.random.rand() + 1j * np.random.rand()\n",
    "    norm = np.sqrt(np.abs(a)**2 + np.abs(b)**2)\n",
    "    return a / norm, b / norm\n",
    "\n",
    "def apply_hadamard(a, b):\n",
    "    \"\"\"Apply Hadamard gate to |ψ⟩ = [a, b]\"\"\"\n",
    "    h = 1 / np.sqrt(2) * np.array([[1, 1], [1, -1]])\n",
    "    input_vec = np.array([a, b])\n",
    "    return h @ input_vec\n",
    "\n",
    "def generate_hadamard_data(n=5000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b = random_qubit_state()\n",
    "        h_out = apply_hadamard(a, b)\n",
    "        p0 = np.abs(h_out[0])**2\n",
    "        p1 = np.abs(h_out[1])**2\n",
    "\n",
    "        rows.append([\n",
    "            a.real, a.imag, b.real, b.imag,\n",
    "            h_out[0].real, h_out[0].imag,\n",
    "            h_out[1].real, h_out[1].imag,\n",
    "            p0, p1\n",
    "        ])\n",
    "    \n",
    "    columns = ['Re(a)', 'Im(a)', 'Re(b)', 'Im(b)',\n",
    "               'Re(Hψ₀)', 'Im(Hψ₀)', 'Re(Hψ₁)', 'Im(Hψ₁)',\n",
    "               'P0', 'P1']\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "df = generate_hadamard_data()\n",
    "path = \"../data/raw/hadamard_data.csv\"\n",
    "df.to_csv(path, index=False)\n",
    "\n",
    "print(f\"✅ Hadamard data saved to: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0a01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ry(θ) data saved to: ../data/raw/ry_rotation_data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def random_qubit_state():\n",
    "    \"\"\"Generate a random normalized single-qubit state\"\"\"\n",
    "    a = np.random.rand() + 1j * np.random.rand()\n",
    "    b = np.random.rand() + 1j * np.random.rand()\n",
    "    norm = np.sqrt(np.abs(a)**2 + np.abs(b)**2)\n",
    "    return a / norm, b / norm\n",
    "\n",
    "def ry_matrix(theta):\n",
    "    \"\"\"Generate the Ry(θ) gate\"\"\"\n",
    "    c = np.cos(theta / 2)\n",
    "    s = np.sin(theta / 2)\n",
    "    return np.array([[c, -s],\n",
    "                     [s,  c]])\n",
    "\n",
    "def apply_ry(a, b, theta):\n",
    "    \"\"\"Apply Ry(θ) gate to the qubit [a, b]\"\"\"\n",
    "    ry = ry_matrix(theta)\n",
    "    state = np.array([a, b])\n",
    "    return ry @ state\n",
    "\n",
    "def generate_ry_data(n=5000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        a, b = random_qubit_state()\n",
    "        theta = np.random.uniform(0, 2 * np.pi)\n",
    "        ry_out = apply_ry(a, b, theta)\n",
    "        p0 = np.abs(ry_out[0])**2\n",
    "        p1 = np.abs(ry_out[1])**2\n",
    "\n",
    "        rows.append([\n",
    "            a.real, a.imag, b.real, b.imag,\n",
    "            theta,\n",
    "            ry_out[0].real, ry_out[0].imag,\n",
    "            ry_out[1].real, ry_out[1].imag,\n",
    "            p0, p1\n",
    "        ])\n",
    "\n",
    "    columns = ['Re(a)', 'Im(a)', 'Re(b)', 'Im(b)', 'θ',\n",
    "               'Re(Ryψ₀)', 'Im(Ryψ₀)', 'Re(Ryψ₁)', 'Im(Ryψ₁)', 'P0', 'P1']\n",
    "\n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "df = generate_ry_data()\n",
    "path = \"../data/raw/ry_rotation_data.csv\"\n",
    "df.to_csv(path, index=False)\n",
    "\n",
    "print(f\"✅ Ry(θ) data saved to: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def4e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved to ../data/raw/pauli_z_expectation_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def generate_pauli_z_expectation_dataset(n_samples: int = 5000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a dataset of Pauli-Z expectation values using Ry(θ) rotations.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples to generate.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with θ and ⟨Z⟩ values.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    thetas = np.random.uniform(0, 2 * np.pi, n_samples)\n",
    "    z_expectations = np.cos(thetas)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"theta\": thetas,\n",
    "        \"z_expectation\": z_expectations\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUTPUT_PATH = \"../data/raw/pauli_z_expectation_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    df = generate_pauli_z_expectation_dataset()\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    print(f\"✅ Dataset saved to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Softmax dataset saved to ../data/raw/softmax_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute softmax values for each set of scores in z.\"\"\"\n",
    "    e_z = np.exp(z - np.max(z))  # for numerical stability\n",
    "    return e_z / e_z.sum(axis=0)\n",
    "\n",
    "def generate_softmax_dataset(n_samples: int = 5000, vector_size: int = 5, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate dataset using softmax transformation.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples (rows).\n",
    "        vector_size (int): Length of the input vector z.\n",
    "        seed (int): Random seed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with input z and softmax(σ(z)).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    raw_data = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        z = np.random.randn(vector_size)\n",
    "        sigma = softmax(z)\n",
    "        row = list(z) + list(sigma)\n",
    "        raw_data.append(row)\n",
    "\n",
    "    columns = [f\"z{i+1}\" for i in range(vector_size)] + [f\"sigma{i+1}\" for i in range(vector_size)]\n",
    "    df = pd.DataFrame(raw_data, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUTPUT_PATH = \"../data/raw/softmax_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    df = generate_softmax_dataset()\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    print(f\"✅ Softmax dataset saved to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32ee822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Entropy Loss dataset saved to ../data/raw/cross_entropy_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute softmax values for input array z.\"\"\"\n",
    "    exp_z = np.exp(z - np.max(z))  # stability trick\n",
    "    return exp_z / exp_z.sum()\n",
    "\n",
    "def cross_entropy_loss(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Compute the cross-entropy loss.\"\"\"\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-15))  # add epsilon for numerical stability\n",
    "\n",
    "def generate_cross_entropy_dataset(n_samples: int = 5000, n_classes: int = 5, seed: int = 42) -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    dataset = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        z = np.random.randn(n_classes)\n",
    "        y_pred = softmax(z)\n",
    "        \n",
    "        y_true = np.zeros(n_classes)\n",
    "        true_class = np.random.randint(0, n_classes)\n",
    "        y_true[true_class] = 1\n",
    "\n",
    "        loss = cross_entropy_loss(y_true, y_pred)\n",
    "\n",
    "        row = list(y_true) + list(y_pred) + [loss]\n",
    "        dataset.append(row)\n",
    "\n",
    "    columns = [f\"y_true_{i+1}\" for i in range(n_classes)] + \\\n",
    "              [f\"y_pred_{i+1}\" for i in range(n_classes)] + \\\n",
    "              [\"loss\"]\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns=columns)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUTPUT_PATH = \"../data/raw/cross_entropy_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    df = generate_cross_entropy_dataset()\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    print(f\"✅ Cross-Entropy Loss dataset saved to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a3281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gradient Descent dataset saved to ../data/raw/gradient_descent_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def quadratic_gradient(theta: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute gradient of a quadratic cost function J(theta) = 0.5 * theta^T * theta\n",
    "    Gradient: ∇J(theta) = theta\n",
    "    \"\"\"\n",
    "    return theta\n",
    "\n",
    "def generate_gradient_descent_dataset(\n",
    "    n_samples: int = 5000,\n",
    "    n_params: int = 5,\n",
    "    learning_rate: float = 0.01,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        theta = np.random.randn(n_params)\n",
    "        grad = quadratic_gradient(theta)\n",
    "        theta_new = theta - learning_rate * grad\n",
    "\n",
    "        record = {}\n",
    "        # Store initial theta\n",
    "        for i in range(n_params):\n",
    "            record[f\"theta_{i+1}\"] = theta[i]\n",
    "        # Store gradient\n",
    "        for i in range(n_params):\n",
    "            record[f\"grad_{i+1}\"] = grad[i]\n",
    "        record[\"learning_rate\"] = learning_rate\n",
    "        # Store updated theta\n",
    "        for i in range(n_params):\n",
    "            record[f\"theta_new_{i+1}\"] = theta_new[i]\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUTPUT_PATH = \"../data/raw/gradient_descent_dataset.csv\"\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "    df = generate_gradient_descent_dataset()\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"✅ Gradient Descent dataset saved to {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
